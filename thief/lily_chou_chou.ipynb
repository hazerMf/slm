{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0082cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: requests in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\djuybu\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\djuybu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b71ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973d9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://www.lily-chou-chou.jp/holic/bbs/htm/index2_mddl.php?ofst=\"\n",
    "START_PAGES = 426828 #start from 427032th pages back to 1\n",
    "LIMIT = 425900 #upto 427000th pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547b5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad26ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== NETWORK =====\n",
    "CONNECT_TIMEOUT = 5\n",
    "READ_TIMEOUT = 120     # offset s√¢u c·∫ßn read timeout d√†i\n",
    "\n",
    "# ===== SPEED CONTROL =====\n",
    "BASE_SLEEP = 3.0     # t·ªëi thi·ªÉu 10s / request\n",
    "JITTER = 5.0          # random th√™m 0‚Äì5s\n",
    "MAX_RETRY = 2         # KH√îNG retry nhi·ªÅu\n",
    "\n",
    "# ===== BLOCK CONTROL =====\n",
    "FAIL_THRESHOLD = 3\n",
    "BLOCK_PAUSE = 5 * 60   # 5 ph√∫t\n",
    "\n",
    "# ===== WINDOW =====\n",
    "WINDOW_SIZE = 100        # crawl r·∫•t s√¢u ‚Üí window nh·ªè\n",
    "\n",
    "# ===== ENCODING =====\n",
    "PAGE_ENCODING = \"euc-jp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a727769",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROGRESS_FILE = \"crawl_progress.json\" # File l∆∞u tr·∫°ng th√°i offset v√† data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "658229c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        try:\n",
    "            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:\n",
    "                checkpoint = json.load(f)\n",
    "                print(f\"üîÑ T√¨m th·∫•y ti·∫øn tr√¨nh c≈©: Offset cu·ªëi c√πng l√† {checkpoint['last_offset']}\")\n",
    "                return checkpoint['last_offset'], checkpoint['post_list']\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è L·ªói ƒë·ªçc file checkpoint, b·∫Øt ƒë·∫ßu m·ªõi: {e}\")\n",
    "    return START_PAGES, []\n",
    "\n",
    "def save_checkpoint(last_offset, post_list):\n",
    "    checkpoint = {\n",
    "        \"last_offset\": last_offset,\n",
    "        \"post_list\": post_list\n",
    "    }\n",
    "    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(checkpoint, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"üíæ ƒê√£ l∆∞u checkpoint t·∫°i offset {last_offset}. T·ªïng s·ªë b√†i: {len(post_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20b8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "POST_LIST = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5de9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ec4db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_offset(ofst: int) -> bool:\n",
    "    url = BASE_URL + str(ofst)\n",
    "    print(f\"[CRAWLING] ofst={ofst}\")\n",
    "\n",
    "    response = None\n",
    "\n",
    "    for attempt in range(MAX_RETRY + 1):\n",
    "        try:\n",
    "            response = session.get(\n",
    "                url,\n",
    "                timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)\n",
    "            )\n",
    "            break\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            wait = BASE_SLEEP * (attempt + 1)\n",
    "            print(f\"[TIMEOUT] ofst={ofst}, wait {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"[ERROR] ofst={ofst}: {e}\")\n",
    "            return False\n",
    "\n",
    "    if response is None or response.status_code != 200:\n",
    "        print(f\"[SKIP] ofst={ofst}\")\n",
    "        return False\n",
    "\n",
    "    if len(response.content) < 800:\n",
    "        print(f\"[SKIP] tiny response at ofst={ofst}\")\n",
    "        return False\n",
    "\n",
    "    response.encoding = PAGE_ENCODING\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    all_trs = soup.find_all('tr')\n",
    "\n",
    "    current_post = {}\n",
    "\n",
    "    for tr in all_trs:\n",
    "        # ===== HEADER =====\n",
    "        header_td = tr.find('td', attrs={'width': '450', 'colspan': '2'})\n",
    "        if header_td and not header_td.has_attr('align'):\n",
    "            fonts = header_td.find_all('font')\n",
    "            if len(fonts) >= 4:\n",
    "                current_post = {}\n",
    "                current_post['user'] = fonts[1].get_text(strip=True)\n",
    "                current_post['post_name'] = fonts[3].get_text(strip=True)\n",
    "\n",
    "        # ===== CONTENT =====\n",
    "        content_td = tr.find(\n",
    "            'td',\n",
    "            attrs={'width': '450', 'colspan': '2', 'align': 'left'}\n",
    "        )\n",
    "        if content_td and 'user' in current_post:\n",
    "            fonts = content_td.find_all('font')\n",
    "            if fonts:\n",
    "                current_post['post_content'] = fonts[0].get_text(strip=True)\n",
    "                POST_LIST.append(current_post)\n",
    "                current_post = {}\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WINDOW] 426828 ‚Üí 426728\n",
      "[CRAWLING] ofst=426828\n",
      "[CRAWLING] ofst=426827\n",
      "[CRAWLING] ofst=426826\n",
      "[CRAWLING] ofst=426825\n",
      "[CRAWLING] ofst=426824\n",
      "[CRAWLING] ofst=426823\n",
      "[CRAWLING] ofst=426822\n",
      "[CRAWLING] ofst=426821\n",
      "[CRAWLING] ofst=426820\n",
      "[CRAWLING] ofst=426819\n",
      "[CRAWLING] ofst=426818\n",
      "[CRAWLING] ofst=426817\n",
      "[CRAWLING] ofst=426816\n",
      "[CRAWLING] ofst=426815\n",
      "[CRAWLING] ofst=426814\n",
      "[CRAWLING] ofst=426813\n",
      "[CRAWLING] ofst=426812\n",
      "[CRAWLING] ofst=426811\n",
      "[CRAWLING] ofst=426810\n",
      "[CRAWLING] ofst=426809\n",
      "[CRAWLING] ofst=426808\n",
      "[CRAWLING] ofst=426807\n",
      "[CRAWLING] ofst=426806\n",
      "[CRAWLING] ofst=426805\n",
      "[CRAWLING] ofst=426804\n",
      "[CRAWLING] ofst=426803\n",
      "[CRAWLING] ofst=426802\n",
      "[CRAWLING] ofst=426801\n",
      "[CRAWLING] ofst=426800\n",
      "[CRAWLING] ofst=426799\n",
      "[CRAWLING] ofst=426798\n",
      "[CRAWLING] ofst=426797\n",
      "[CRAWLING] ofst=426796\n",
      "[CRAWLING] ofst=426795\n",
      "[CRAWLING] ofst=426794\n",
      "[CRAWLING] ofst=426793\n",
      "[CRAWLING] ofst=426792\n",
      "[CRAWLING] ofst=426791\n",
      "[CRAWLING] ofst=426790\n",
      "[CRAWLING] ofst=426789\n",
      "[CRAWLING] ofst=426788\n",
      "[CRAWLING] ofst=426787\n",
      "[CRAWLING] ofst=426786\n",
      "[CRAWLING] ofst=426785\n",
      "[CRAWLING] ofst=426784\n",
      "[CRAWLING] ofst=426783\n",
      "[CRAWLING] ofst=426782\n",
      "[CRAWLING] ofst=426781\n",
      "[CRAWLING] ofst=426780\n",
      "[CRAWLING] ofst=426779\n",
      "[CRAWLING] ofst=426778\n",
      "[CRAWLING] ofst=426777\n",
      "[CRAWLING] ofst=426776\n",
      "[CRAWLING] ofst=426775\n",
      "[CRAWLING] ofst=426774\n",
      "[CRAWLING] ofst=426773\n",
      "[CRAWLING] ofst=426772\n",
      "[CRAWLING] ofst=426771\n",
      "[CRAWLING] ofst=426770\n",
      "[CRAWLING] ofst=426769\n",
      "[CRAWLING] ofst=426768\n",
      "[CRAWLING] ofst=426767\n",
      "[CRAWLING] ofst=426766\n",
      "[CRAWLING] ofst=426765\n",
      "[CRAWLING] ofst=426764\n",
      "[CRAWLING] ofst=426763\n",
      "[CRAWLING] ofst=426762\n",
      "[CRAWLING] ofst=426761\n",
      "[CRAWLING] ofst=426760\n",
      "[CRAWLING] ofst=426759\n",
      "[CRAWLING] ofst=426758\n",
      "[CRAWLING] ofst=426757\n",
      "[CRAWLING] ofst=426756\n",
      "[CRAWLING] ofst=426755\n",
      "[CRAWLING] ofst=426754\n",
      "[CRAWLING] ofst=426753\n",
      "[CRAWLING] ofst=426752\n",
      "[CRAWLING] ofst=426751\n",
      "[CRAWLING] ofst=426750\n",
      "[CRAWLING] ofst=426749\n",
      "[CRAWLING] ofst=426748\n",
      "[CRAWLING] ofst=426747\n",
      "[CRAWLING] ofst=426746\n",
      "[CRAWLING] ofst=426745\n",
      "[CRAWLING] ofst=426744\n",
      "[CRAWLING] ofst=426743\n",
      "[CRAWLING] ofst=426742\n",
      "[CRAWLING] ofst=426741\n",
      "[CRAWLING] ofst=426740\n",
      "[CRAWLING] ofst=426739\n",
      "[CRAWLING] ofst=426738\n",
      "[CRAWLING] ofst=426737\n",
      "[CRAWLING] ofst=426736\n",
      "[CRAWLING] ofst=426735\n",
      "[CRAWLING] ofst=426734\n",
      "[CRAWLING] ofst=426733\n",
      "[CRAWLING] ofst=426732\n",
      "[CRAWLING] ofst=426731\n",
      "[CRAWLING] ofst=426730\n",
      "[CRAWLING] ofst=426729\n",
      "\n",
      "[WINDOW DONE] ƒê√£ xong window t·ªõi offset 426728\n",
      "üíæ ƒê√£ l∆∞u checkpoint t·∫°i offset 426728. T·ªïng s·ªë b√†i: 4000\n",
      "‚òï Ngh·ªâ d√†i gi·ªØa c√°c window... 5 ph√∫t\n",
      "\n",
      "[WINDOW] 426728 ‚Üí 426628\n",
      "[CRAWLING] ofst=426728\n",
      "[CRAWLING] ofst=426727\n",
      "[CRAWLING] ofst=426726\n",
      "[CRAWLING] ofst=426725\n",
      "[CRAWLING] ofst=426724\n",
      "[CRAWLING] ofst=426723\n",
      "[CRAWLING] ofst=426722\n",
      "[CRAWLING] ofst=426721\n",
      "[CRAWLING] ofst=426720\n",
      "[CRAWLING] ofst=426719\n",
      "[CRAWLING] ofst=426718\n",
      "[CRAWLING] ofst=426717\n",
      "[CRAWLING] ofst=426716\n",
      "[CRAWLING] ofst=426715\n",
      "[CRAWLING] ofst=426714\n",
      "[CRAWLING] ofst=426713\n",
      "[CRAWLING] ofst=426712\n",
      "[CRAWLING] ofst=426711\n",
      "[CRAWLING] ofst=426710\n",
      "[CRAWLING] ofst=426709\n",
      "[CRAWLING] ofst=426708\n",
      "[CRAWLING] ofst=426707\n",
      "[CRAWLING] ofst=426706\n",
      "[CRAWLING] ofst=426705\n",
      "[CRAWLING] ofst=426704\n",
      "[CRAWLING] ofst=426703\n",
      "[CRAWLING] ofst=426702\n",
      "[CRAWLING] ofst=426701\n",
      "[CRAWLING] ofst=426700\n",
      "[CRAWLING] ofst=426699\n",
      "[CRAWLING] ofst=426698\n",
      "[CRAWLING] ofst=426697\n",
      "[CRAWLING] ofst=426696\n",
      "[CRAWLING] ofst=426695\n",
      "[CRAWLING] ofst=426694\n",
      "[CRAWLING] ofst=426693\n",
      "[CRAWLING] ofst=426692\n",
      "[CRAWLING] ofst=426691\n",
      "[CRAWLING] ofst=426690\n",
      "[CRAWLING] ofst=426689\n",
      "[CRAWLING] ofst=426688\n",
      "[CRAWLING] ofst=426687\n",
      "[CRAWLING] ofst=426686\n",
      "[CRAWLING] ofst=426685\n",
      "[CRAWLING] ofst=426684\n",
      "[CRAWLING] ofst=426683\n",
      "[CRAWLING] ofst=426682\n",
      "[CRAWLING] ofst=426681\n",
      "[CRAWLING] ofst=426680\n",
      "[CRAWLING] ofst=426679\n",
      "[CRAWLING] ofst=426678\n",
      "[CRAWLING] ofst=426677\n",
      "[CRAWLING] ofst=426676\n",
      "[CRAWLING] ofst=426675\n",
      "[CRAWLING] ofst=426674\n",
      "[CRAWLING] ofst=426673\n",
      "[CRAWLING] ofst=426672\n",
      "[CRAWLING] ofst=426671\n",
      "[CRAWLING] ofst=426670\n",
      "[CRAWLING] ofst=426669\n",
      "[CRAWLING] ofst=426668\n",
      "[CRAWLING] ofst=426667\n",
      "[CRAWLING] ofst=426666\n",
      "[CRAWLING] ofst=426665\n",
      "[CRAWLING] ofst=426664\n",
      "[CRAWLING] ofst=426663\n",
      "[CRAWLING] ofst=426662\n",
      "[CRAWLING] ofst=426661\n",
      "[CRAWLING] ofst=426660\n",
      "[CRAWLING] ofst=426659\n",
      "[CRAWLING] ofst=426658\n",
      "[CRAWLING] ofst=426657\n",
      "[CRAWLING] ofst=426656\n",
      "[CRAWLING] ofst=426655\n",
      "[CRAWLING] ofst=426654\n",
      "[CRAWLING] ofst=426653\n",
      "[CRAWLING] ofst=426652\n",
      "[CRAWLING] ofst=426651\n",
      "[CRAWLING] ofst=426650\n",
      "[CRAWLING] ofst=426649\n",
      "[CRAWLING] ofst=426648\n",
      "[CRAWLING] ofst=426647\n",
      "[CRAWLING] ofst=426646\n",
      "[CRAWLING] ofst=426645\n",
      "[CRAWLING] ofst=426644\n",
      "[CRAWLING] ofst=426643\n",
      "[CRAWLING] ofst=426642\n",
      "[CRAWLING] ofst=426641\n",
      "[CRAWLING] ofst=426640\n",
      "[CRAWLING] ofst=426639\n",
      "[CRAWLING] ofst=426638\n",
      "[CRAWLING] ofst=426637\n",
      "[CRAWLING] ofst=426636\n",
      "[CRAWLING] ofst=426635\n",
      "[CRAWLING] ofst=426634\n",
      "[CRAWLING] ofst=426633\n",
      "[CRAWLING] ofst=426632\n",
      "[CRAWLING] ofst=426631\n",
      "[CRAWLING] ofst=426630\n",
      "[CRAWLING] ofst=426629\n",
      "\n",
      "[WINDOW DONE] ƒê√£ xong window t·ªõi offset 426628\n",
      "üíæ ƒê√£ l∆∞u checkpoint t·∫°i offset 426628. T·ªïng s·ªë b√†i: 8000\n",
      "‚òï Ngh·ªâ d√†i gi·ªØa c√°c window... 5 ph√∫t\n",
      "\n",
      "[WINDOW] 426628 ‚Üí 426528\n",
      "[CRAWLING] ofst=426628\n",
      "[CRAWLING] ofst=426627\n",
      "[CRAWLING] ofst=426626\n",
      "[CRAWLING] ofst=426625\n",
      "[CRAWLING] ofst=426624\n",
      "[CRAWLING] ofst=426623\n",
      "[CRAWLING] ofst=426622\n",
      "[CRAWLING] ofst=426621\n",
      "[CRAWLING] ofst=426620\n",
      "[CRAWLING] ofst=426619\n",
      "[CRAWLING] ofst=426618\n",
      "[CRAWLING] ofst=426617\n",
      "[CRAWLING] ofst=426616\n",
      "[CRAWLING] ofst=426615\n",
      "[CRAWLING] ofst=426614\n",
      "[CRAWLING] ofst=426613\n",
      "[CRAWLING] ofst=426612\n",
      "[CRAWLING] ofst=426611\n",
      "[CRAWLING] ofst=426610\n",
      "[CRAWLING] ofst=426609\n",
      "[CRAWLING] ofst=426608\n",
      "[CRAWLING] ofst=426607\n",
      "[CRAWLING] ofst=426606\n",
      "[CRAWLING] ofst=426605\n",
      "[CRAWLING] ofst=426604\n"
     ]
    }
   ],
   "source": [
    "# T·∫£i ti·∫øn tr√¨nh c≈© n·∫øu c√≥\n",
    "current_start_offset, POST_LIST = load_checkpoint()\n",
    "\n",
    "consecutive_failures = 0\n",
    "\n",
    "# Duy·ªát theo t·ª´ng window\n",
    "for window_start in range(current_start_offset, LIMIT, -WINDOW_SIZE):\n",
    "    window_end = max(window_start - WINDOW_SIZE, LIMIT)\n",
    "    \n",
    "    print(f\"\\n[WINDOW] {window_start} ‚Üí {window_end}\")\n",
    "\n",
    "    for ofst in range(window_start, window_end, -1):\n",
    "        ok = crawl_offset(ofst)\n",
    "\n",
    "        if not ok:\n",
    "            consecutive_failures += 1\n",
    "            print(f\"[FAIL] consecutive={consecutive_failures}\")\n",
    "        else:\n",
    "            consecutive_failures = 0\n",
    "\n",
    "        # X·ª≠ l√Ω khi b·ªã block\n",
    "        if consecutive_failures >= FAIL_THRESHOLD:\n",
    "            print(\"\\nüö® [BLOCK DETECTED]\")\n",
    "            # L∆∞u l·∫°i v·ªã tr√≠ hi·ªán t·∫°i tr∆∞·ªõc khi ngh·ªâ\n",
    "            save_checkpoint(ofst, POST_LIST) \n",
    "            print(f\"‚è∏ T·∫°m ngh·ªâ {BLOCK_PAUSE//60} ph√∫t...\")\n",
    "            time.sleep(BLOCK_PAUSE)\n",
    "            consecutive_failures = 0\n",
    "            break\n",
    "\n",
    "        sleep_time = BASE_SLEEP + random.random() * JITTER\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    # SAU M·ªñI WINDOW: Ghi ƒë√® v√†o file JSON ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng m·∫•t d·ªØ li·ªáu\n",
    "    print(f\"\\n[WINDOW DONE] ƒê√£ xong window t·ªõi offset {window_end}\")\n",
    "    save_checkpoint(window_end, POST_LIST)\n",
    "    \n",
    "    # Ngh·ªâ d√†i gi·ªØa c√°c window\n",
    "    print(f\"‚òï Ngh·ªâ d√†i gi·ªØa c√°c window... {BLOCK_PAUSE//60} ph√∫t\")\n",
    "    time.sleep(BLOCK_PAUSE)\n",
    "\n",
    "print(f\"[DONE] Ho√†n t·∫•t crawl. T·ªïng s·ªë b√†i: {len(POST_LIST)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e32668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('lily_chou_chou_posts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(POST_LIST, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
